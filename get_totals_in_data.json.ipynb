{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n------------------------------------------------\\n---  A note about comparison techniques used ---\\n------------------------------------------------\\njson_delta is best for serializing/deserializing structures and\\nminimizing comm overhead.  It's may not be ideal for specialized\\ncomparison of existing JSON\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "'''\n",
    "------------------------------------------------\n",
    "---  A note about comparison techniques used ---\n",
    "------------------------------------------------\n",
    "json_delta is best for serializing/deserializing structures and\n",
    "minimizing comm overhead.  It's may not be ideal for specialized\n",
    "comparison of existing JSON\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#--- Test it ---\\nparse_date(\"snapshots/HealthData.gov_2014-02-24_data.json\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_date(file_name):\n",
    "    \n",
    "    starting_point_of_date = \"_20\"\n",
    "    date_pos_start = file_name.find(starting_point_of_date)+1\n",
    "    return file_name[date_pos_start:date_pos_start+10]\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#--- Test it ---\n",
    "parse_date(\"snapshots/HealthData.gov_2014-02-24_data.json\")\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# --- Experiment with keys ---\\nif \"bureauCode\"  in json_data_list[0][0]: print json_data_list[0][0][\"bureauCode\"]\\nif \"publisher\"   in json_data_list[0][0]: print json_data_list[0][0][\"publisher\"]\\nif \"landingPage\" in json_data_list[0][0]: print json_data_list[0][0][\"landingPage\"]\\nprint json.dumps(json_data_list[0][0], sort_keys=False, indent=4)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "------------------------------------------------\n",
    "---  Capturing agency counts                 ---\n",
    "------------------------------------------------\n",
    "Many dataset entries lack bureauCode.  \n",
    "So perhaps other identifiers can be used as a proxy\n",
    "'''\n",
    "\n",
    "\n",
    "# Pull out the most important elements to tally on\n",
    "def get_keys(dataset):\n",
    "    keys = [\"bureauCode\", \"publisher\", \"landingPage\",\"modified\"]\n",
    "    key_values = []\n",
    "    for i,key in enumerate(keys):\n",
    "        if key in dataset:\n",
    "            key_values.append(dataset[key])\n",
    "        else:\n",
    "            key_values.append(None)\n",
    "    return dict(zip(keys, key_values))\n",
    "        \n",
    "\n",
    "'''\n",
    "#--- Test it ---\n",
    "print get_keys(json_data_list[0][0])\n",
    "'''\n",
    "'''\n",
    "# --- Experiment with keys ---\n",
    "if \"bureauCode\"  in json_data_list[0][0]: print json_data_list[0][0][\"bureauCode\"]\n",
    "if \"publisher\"   in json_data_list[0][0]: print json_data_list[0][0][\"publisher\"]\n",
    "if \"landingPage\" in json_data_list[0][0]: print json_data_list[0][0][\"landingPage\"]\n",
    "print json.dumps(json_data_list[0][0], sort_keys=False, indent=4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# FIXME: Code not yet finished\n",
    "# FIXME: Should call get_keys\n",
    "# Create a dictionary of values for comparison\n",
    "\n",
    "def get_key_list(dataset_list):\n",
    "    key_list = []\n",
    "    for index, dataset in enumerate(dataset_list):\n",
    "        key_list.append(get_keys(dataset))\n",
    "    #for # List of unique bureauCode values    \n",
    "    \n",
    "    totals = len(dataset_list)\n",
    "    #print get_keys(dataset[0])\n",
    "    return key_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'009:25': 44, '009:15': 19, '009:92': 7, '009:10': 151, '009:75': 6, '009:20': 243, '009:30': 11, '009:17': 1, '009:70': 81, '009:00': 679, '009:38': 551, '009:33': 14}\n"
     ]
    }
   ],
   "source": [
    "def get_agency_counts(key_list):\n",
    "    agency_counts = {}\n",
    "    for index,key_item in enumerate(key_list):\n",
    "\n",
    "        agencies = key_item[\"bureauCode\"]\n",
    "\n",
    "        # Just in case it's not a list, make it one\n",
    "        agencies = agencies if isinstance(agencies,list) else [agencies]\n",
    "\n",
    "        for agency in agencies:\n",
    "            agency = agency.encode('ascii','ignore')\n",
    "            agency_counts[agency] = agency_counts.get(agency, 0) + 1\n",
    "            \n",
    "    return agency_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\n#--- Test it ---\\nprint support_old_schema(dataset)\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def support_old_schema(dataset_list):\n",
    "    if isinstance(dataset_list, dict):\n",
    "        return dataset_list[\"dataset\"]\n",
    "    elif isinstance(dataset, list):\n",
    "        return dataset_list\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "'''    \n",
    "#--- Test it ---\n",
    "print support_old_schema(dataset)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-01: {'009:25': 44, '009:15': 19, '009:92': 7, '009:10': 151, '009:75': 6, '009:20': 243, '009:30': 11, '009:17': 1, '009:70': 81, '009:00': 679, '009:38': 551, '009:33': 14}\n",
      "\n",
      "2015-11-30: {'009:25': 44, '009:15': 19, '009:92': 7, '009:10': 151, '009:75': 6, '009:20': 243, '009:30': 11, '009:17': 1, '009:70': 81, '009:00': 679, '009:38': 551, '009:33': 14}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob   # Wildcard search\n",
    "import json\n",
    "\n",
    "def load_file(file_name):\n",
    "    with open(file_name) as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "        return json_data\n",
    "        print(\"Loaded file: \"+file_name)\n",
    "\n",
    "\n",
    "#FIXME: Need to find agency decode\n",
    "#       Examples: {'009:25', '009:15', '009:92', '009:10', '009:75',\n",
    "#                  '009:20', '009:30', '009:17', '009:70', '009:00', \n",
    "#                  '009:38', '009:33'}\n",
    "def main():\n",
    "    file_pattern = \"snapshots/\"\n",
    "    file_pattern += \"HealthData.gov[_][0-9][0-9][0-9][0-9][-][0-9][0-9][-][0-9][0-9][_]data.json\"\n",
    "    file_name_list = glob.glob(file_pattern)\n",
    "\n",
    "    datasets = []\n",
    "    for index, file_name in enumerate(reversed(file_name_list)):\n",
    "\n",
    "        snapshot_date = parse_date(file_name)\n",
    "        dataset_list = load_file(file_name)\n",
    "        dataset_list = support_old_schema(dataset)\n",
    "\n",
    "        key_list      = get_key_list(dataset_list)\n",
    "        agency_counts = get_agency_counts(key_list)\n",
    "\n",
    "        print snapshot_date+\": \"+str(agency_counts)+\"\\n\"\n",
    "\n",
    "        if index > 0: break  # Don't run all for debugging\n",
    "\n",
    "            \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
